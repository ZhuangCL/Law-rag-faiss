# _________________________________________________OPENAI LLM
import faiss
import json
import openai
from scripts.embed_text import embed_text  # ä½ è‡ªå·±å®šç¾©å¥½çš„ embedding å‡½æ•¸
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain

# è¨­å®š OpenAI API é‡‘é‘°
import config
openai.api_key = config.OPENAI_API_KEY

# å»ºç«‹ LangChain LLM (å°æ‡‰ gpt-3.5-turbo)
llm = ChatOpenAI(model_name="gpt-3.5-turbo", api_key = config.OPENAI_API_KEY,temperature=0)

# è¼‰å…¥ FAISS ç´¢å¼•
index = faiss.read_index("embeddings/traffic_faiss.index")
with open('scripts/law/data/traffic_raw.json', 'r', encoding='utf-8') as f:
    laws_data = json.load(f)

# å®šç¾© Prompt æ¨¡æ¿
keyword_prompt = PromptTemplate(
    input_variables=["query"],
    template=(
        "è«‹æ ¹æ“šä¸‹åˆ—å•é¡Œï¼Œæå–å­—æ•¸ä¸è¶…é1çš„é—œéµå­—ï¼Œç”¨é€—è™Ÿåˆ†éš”ã€‚\n"
        "å•é¡Œï¼š{query}"
    )
)
keyword_chain = LLMChain(prompt=keyword_prompt, llm=llm)
# åˆ‡å‰²é—œéµå­—
def extract_keywords(query):
    response = keyword_chain.run(query)
    keywords = [kw.strip() for kw in response.split(",") if kw.strip()]
    return keywords


# FAISS æœå°‹æ³•æ¢
def search_law(query, k=20):
    # å°‡æŸ¥è©¢è½‰æ›ç‚ºåµŒå…¥å‘é‡
    query_vector = embed_text(query)

    # åœ¨ FAISS ä¸­æª¢ç´¢æœ€ç›¸ä¼¼çš„æ³•æ¢
    D, I = index.search(query_vector.reshape(1, -1), k)

    # è¿”å›æª¢ç´¢åˆ°çš„æ³•æ¢
    return I

from tqdm import tqdm
def print_law(law_indexes, keywords):
    for i in tqdm(law_indexes[0]):
        law = laws_data[i]
        law_text = f"{law['title']} {law['content']}"
        
        if all(keyword in law_text for keyword in keywords):
            print(f"âœ… æ‰¾åˆ°ç›¸é—œæ³•æ¢ğŸ“„ï¼š{law_text}")
